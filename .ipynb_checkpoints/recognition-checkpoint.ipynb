{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "x_dim = 100\n",
    "y_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Splitting the dataset into train and test folders. Please create test and train dir in the given path before running this.\n",
    "\n",
    "def delete_contents(folder): # function to delete the files in a dir\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "def get_files_from_folder(path): #Returns all the files and folders in a given path.\n",
    "\n",
    "    files = os.listdir(path)\n",
    "    return np.asarray(files)\n",
    "\n",
    "def main(path_to_data, path_to_test_data, path_to_train_data, train_ratio):\n",
    "    # get dirs\n",
    "    _, dirs, _ = next(os.walk(path_to_data))\n",
    "\n",
    "    # calculates how many train data per class\n",
    "    data_counter_per_class = np.zeros((len(dirs)))\n",
    "    for i in range(len(dirs)):\n",
    "        path = os.path.join(path_to_data, dirs[i])\n",
    "        files = get_files_from_folder(path)\n",
    "        data_counter_per_class[i] = len(files)\n",
    "    test_counter = np.round(data_counter_per_class * (1 - train_ratio))\n",
    "    train_counter = np.round(data_counter_per_class * train_ratio)\n",
    "\n",
    "    # transfers files\n",
    "    for i in range(len(dirs)):\n",
    "        path_to_original = os.path.join(path_to_data, dirs[i])\n",
    "\n",
    "        #creates dir\n",
    "        # Kavya : better if checked outside the for loop\n",
    "        if not os.path.exists(path_to_test_data):\n",
    "            os.makedirs(path_to_test_data)\n",
    "        if not os.path.exists(path_to_train_data):\n",
    "            os.makedirs(path_to_train_data)\n",
    "            \n",
    "        files = get_files_from_folder(path_to_original)\n",
    "        random.shuffle(files)\n",
    "        # moves data\n",
    "        for j in range(int(test_counter[i])):\n",
    "            dst = os.path.join(path_to_test_data, files[j])\n",
    "            src = os.path.join(path_to_original, files[j])\n",
    "            shutil.copy(src, dst)\n",
    "        #files = get_files_from_folder(path_to_original)\n",
    "        #random.shuffle(files)\n",
    "        for j in range(int(test_counter[i]),len(files)):\n",
    "            dst = os.path.join(path_to_train_data, files[j])\n",
    "            src = os.path.join(path_to_original, files[j])\n",
    "            shutil.copy(src, dst)\n",
    "if __name__ == \"__main__\":\n",
    "    delete_contents('./train')\n",
    "    delete_contents('./test')\n",
    "    main('./Images_face94','./test','./train',0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path for the training images\n",
    "\n",
    "Path = './train/'\n",
    "files = os.listdir(Path)\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-94afa87f4f60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./train/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "#Converting each image to Grayscale and appending the data to images\n",
    "\n",
    "images = []\n",
    "\n",
    "for name in files:\n",
    "    temp = cv2.imread('./train/'+name)\n",
    "    temp = cv2.cvtColor(temp,cv2.COLOR_BGR2GRAY)\n",
    "    temp = cv2.resize(temp, (x_dim,y_dim), interpolation = cv2.INTER_AREA)\n",
    "    images.append(temp.flatten())\n",
    "        \n",
    "# total number of images considered : 360 - 5 of each person\n",
    "# images converted to grayscale of size : (100,100)\n",
    "\n",
    "# images : rows - 360\n",
    "#          columns - 100*100 = 10000\n",
    "# images.shape : (360,10000)\n",
    "\n",
    "# temp.shape : (100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean of images\n",
    "\n",
    "images = np.array(images)\n",
    "image_mean = images.mean(axis = 0)\n",
    "images = images - image_mean\n",
    "images = images.T\n",
    "# transpose of images taken to find eigen vectors of matrix A'A\n",
    "\n",
    "# image_mean.shape : (100000,)\n",
    "# images.shape : (10000, 360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVD function\n",
    "#u is the basis of eigen faces\n",
    "\n",
    "u,s,v = np.linalg.svd(images, full_matrices=False)\n",
    "\n",
    "# u.shape : (10000, 360)\n",
    "# There are 360 eigen faces currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.shape)\n",
    "x1 = range(1,s.shape[0]+1)\n",
    "y1 = s\n",
    "#Plot a line graph\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax1.plot(x1, y1, marker='o')\n",
    "ax1.axhline(y=s[240], xmin=0, xmax=images.shape[1], ls='--')\n",
    "ax1.axvline(x=240, ymin=0, ymax=s[240], ls='--')\n",
    "x_ticks = np.append(ax1.get_xticks(), 240)\n",
    "y_ticks = np.append(ax1.get_yticks(), s[240])\n",
    "ax1.set_xticks(x_ticks)\n",
    "ax1.set_yticks(y_ticks)\n",
    "ax1.set_title(\"Scree plot\")\n",
    "ax1.set(xlabel=\"Component number\",ylabel=\"Singular Values\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the unwanted columns in U matrix to form the feature matrix.\n",
    "u = u[:,:240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dot product of all the images and U matrix to find the projection co-efficients\n",
    "\n",
    "dot_train = np.empty(shape = (u.shape[1], images.shape[1]),  dtype=np.int8) #360 by 360\n",
    "temp = np.empty(shape = (1, u.shape[1]),  dtype=np.int8) #1 by 360\n",
    "\n",
    "# dot_train.shape : (120, 720)\n",
    "# temp.shape : (1, 120)\n",
    "# images.shape : (10000, 720)\n",
    "\n",
    "for i in range(images.shape[1]):    # i from 0 to 360\n",
    "    for c in range(u.shape[1]):    # c from 0 to 360\n",
    "        temp[0,c] = np.sum(images[:,i] * u[:,c])\n",
    "        \n",
    "    dot_train[:, i] = temp[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPEAT THE EXECUTION OF CODE BELOW FOR NEW INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path for the training images\n",
    "\n",
    "Path = './test/'\n",
    "tfiles = os.listdir(Path)\n",
    "tfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "\n",
    "for name in tfiles:\n",
    "    temp = cv2.imread('./test/'+name)\n",
    "    temp = cv2.cvtColor(temp,cv2.COLOR_BGR2GRAY)\n",
    "    temp = cv2.resize(temp, (x_dim,y_dim), interpolation = cv2.INTER_AREA)\n",
    "    test_images.append(temp.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Substracting mean\n",
    "test_images = np.array(test_images)\n",
    "test_images = test_images - image_mean\n",
    "test_images = test_images.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dot product of test image and U matrix\n",
    "\n",
    "dot_test = np.empty(shape = (u.shape[1], test_images.shape[1]), dtype=np.int8)\n",
    "temp = np.empty(shape = (1, u.shape[1]),  dtype=np.int8)\n",
    "    \n",
    "for i in range(test_images.shape[1]):    # i from 0 to 432\n",
    "    for c in range(u.shape[1]):    # c from 0 to 240\n",
    "        temp[0,c] = np.sum(test_images[:,i] * u[:,c])\n",
    "    dot_test[:, i] = temp[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the variation between input image and test images\n",
    "answer = np.empty(shape=(dot_train.shape[1],dot_test.shape[1]))\n",
    "for i in range(dot_test.shape[1]):\n",
    "    sub = np.empty(shape = (u.shape[1], dot_train.shape[1]), dtype=np.int8)\n",
    "    for col in range(dot_train.shape[1]):\n",
    "        sub[:,col] = dot_train[:,col] - dot_test[:,i]\n",
    "    for c in range(sub.shape[1]):    \n",
    "        answer[c,i] = np.linalg.norm(sub[:,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_index(temp):\n",
    "    m = 0\n",
    "    for i in range(len(temp)):\n",
    "        if temp[i]<temp[m]:\n",
    "            m = i\n",
    "    return m\n",
    "\n",
    "# Kavya : using sort() function would be more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FACE RECOGNITION\n",
    "temp_ans = np.empty(shape=(answer.shape[1],),dtype=int)\n",
    "temp = np.empty(shape=(answer.shape[0],))\n",
    "for i in range(0,answer.shape[1]):\n",
    "    temp = answer[:,i]\n",
    "    temp_ans[i] = min_index(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = 0\n",
    "total = test_images.shape[1]\n",
    "for i in range(temp_ans.shape[0]):\n",
    "    if tfiles[i].split(\".\")[0] == files[temp_ans[i]].split(\".\")[0]:\n",
    "        right+=1\n",
    "    else:\n",
    "        print(tfiles[i].split(\".\")[0],files[temp_ans[i]].split(\".\")[0])\n",
    "eff = (right/total)*100\n",
    "print(\"Efficiency: \",eff,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(917,)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_ans.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 917)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
